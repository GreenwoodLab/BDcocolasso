---
title: "Introduction-to-BDcocolasso"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Introduction-to-BDcocolasso}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

## Quick Start

We will use the simulated data which ships with the package and can be loaded via:

```{r}
library(BDcocolasso)
data("simulated_data_missing")
data("simulated_data_additive")
data("simulated_data_missing_block")
data("simulated_data_additive_block")
```

These datasets correspond to corrupted datasets in additive error setting and missing data setting, and to partially corrupted datasets in additive error setting and missing data setting. In the missing data setting, those datasets contain NAs values, whereas in the additive error setting, they do not contain NAs values but the covariates are measured with error. 
We will note that it is essential to know the standard deviation corresponding to the additive error matrix in the additive error setting, in order to run the CoCoLasso algorithm.

## CoCoLasso algorithm

We can first perform classic CoCoLasso algorithm. To do that, it is important to note that the datasets must be converted to a matrix:

```{r}
y_missing <- simulated_data_missing[,1]
Z_missing = simulated_data_missing[,2:dim(simulated_data_missing)[2]]
Z_missing = as.matrix(Z_missing)
n_missing <- dim(Z_missing)[1]
p_missing <- dim(Z_missing)[2]
y_missing = as.matrix(y_missing)
```

We can then fit the CoCoLasso model to our data. It is important to specify the type of noise (additive or missing) and the use of CoCoLasso (block=FALSE) or BD-CoCoLasso (block=TRUE). Here, `noise` is equal to `missing` because we have NAs values in the dataset :
```{r}

fit_missing = coco(Z=Z_missing,y=y_missing,n=n_missing,p=p_missing,step=100,K=4,mu=10,tau=NULL, etol = 1e-4,noise = "missing",block=FALSE)
```

It is possible to print the fitted object, so as to display the evolution of mean-squared error in function of lambda values:
```{r}
print(fit_missing)

```

It is also possible to display the coefficients obtained for all values of lambda, or for specific values of lambda.
```{r}
coef(fit_missing, s=fit_missing$lambda.opt)
```

It is also possible to obtain a prediction for new covariates values. Let's simulate values following the same simulation pattern used to obtain Z_missing, and look at the obtained prediction. Default configuration is using coefficients for lambda.sd:

```{r}
cov = cov_autoregressive(p_missing)
X = MASS::mvrnorm(1,mu=rep(0,p_missing),Sigma=cov)
beta = c(3,2,0,0,1.5,rep(0,p_missing - 5))
y = X %*% beta + rnorm(1,0,2)

y_predict.sd <- predict(fit_missing, newx = X, type="response")
y_predict.sd

```

But it is also possible to specify the lambda value at which we wish to calculate the prediction:
```{r}
y_predict.opt <- predict(fit_missing, newx = X, type="response", lambda.pred = fit_missing$lambda.opt)
y_predict.opt
```

It is then possible to visualize the solution path of the coefficients:
```{r}
plotCoef(fit_missing)
```

It is also possible to visualize the mean-squared error for all values of lambda:
```{r}
plotError(fit_missing)
```
In red is the mean squared error (without the constant term, which is why we obtain negative values), and in black are the standard deviations for each error value.
On each of the plots, the left dashed line represent the optimum lambda, while the right dashed line represent the lambda corresponding to the one-standard-error rule.

We can do the same with additive error setting :
```{r}
y_additive <- simulated_data_additive[,1]
Z_additive = simulated_data_additive[,2:dim(simulated_data_additive)[2]]
Z_additive = as.matrix(Z_additive)
n_additive <- dim(Z_additive)[1]
p_additive <- dim(Z_additive)[2]
y_additive = as.matrix(y_additive)

```

Let's fit CoCoLasso:
```{r}


fit_additive = coco(Z=Z_additive,y=y_additive,n=n_additive,p=p_additive,center.Z = FALSE, step=100,K=4,mu=10,tau=0.3,etol = 1e-4,noise = "additive", block=FALSE)

```

Here, we do not center Z because it is not necessary and it might lead to introducing bias, because of the additive error setting. It is very important to know (or estimate) \code{tau} parameter corresponding to the standard deviation of the error matrix. Without it, the algorithm cannot run. In our example with simulated data, \code{tau} is equal to `0.3`.

We can plot coefficients and the mean-squared-error:
```{r}
plotCoef(fit_additive)
plotError(fit_additive)
```



## Block-Descent CoCoLasso algorithm

The BDCoCoLasso algorithms functions the same way. We can fit the model for both datasets. We have to be careful to use \code{block=TRUE}:
```{r}
p1 <- 180
p2 <- 20
y_missing <- simulated_data_missing_block[,1]
Z_missing = simulated_data_missing_block[,2:dim(simulated_data_missing_block)[2]]
Z_missing = as.matrix(Z_missing)
n_missing <- dim(Z_missing)[1]
p_missing <- dim(Z_missing)[2]
y_missing = as.matrix(y_missing)

fit_missing = coco(Z=Z_missing,y=y_missing,n=n_missing,p=p_missing,p1=p1,p2=p2,step=100,K=4,mu=10,tau=NULL,noise="missing",block=TRUE)

y_additive <- simulated_data_additive_block[,1]
Z_additive = simulated_data_additive_block[,2:dim(simulated_data_additive_block)[2]]
Z_additive = as.matrix(Z_additive)
n_additive <- dim(Z_additive)[1]
p_additive <- dim(Z_additive)[2]
y_additive = as.matrix(y_additive)

fit_additive = coco(Z=Z_additive,y=y_additive,n=n_additive,p=p_additive,p1=p1,p2=p2,center.Z = FALSE, step=100,K=4,mu=10,tau=0.3,noise="additive",block=TRUE)


```

Note that the algorithm requires that the first p1 columns of Z be the uncorrupted covariates, and the last p2 columns be the corrupted covariates.
It it also important to keep in mind that this algorithm has a relatively high computational cost. In the example given above, it is normal that code should run for a dozens seconds before obtaining a result. It also requires a big amount of memory when the number of features reaches the thousands.

We can plot the coefficients and the error for the missing data scenario. Here we should expect to have 6 non-zero coefficients, with pairs of coefficient having similar values, since data was simulated with beta = c(3,2,0,0,1.5,0,...,0,1.5,0,0,2,3).
```{r}
plotCoef(fit_missing)
plotError(fit_missing)
plotCoef(fit_additive)
plotError(fit_additive)
```

One important remark : using too important missing rate may lead to a disfunctionement of the algorithms. If the error "eigen(W, symmetric=TRUE) : infinite or NaN values" appears, this may indicate that you used a matrix with too important missing rates. A good threshold for missing values is 0.5.
